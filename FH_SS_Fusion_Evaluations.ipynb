{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A universal framework for fusing semantic information and temporal consistency for background segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrate the evaluation process of the propose model, one can reproduce the results given in the paper. In addition, more details regarding the evaluation process are given here.\n",
    "\n",
    "---by Zhi Zeng Sep,28,2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal consistency based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Check paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check paths for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = './Ours_Dataset'\n",
    "print('dataset_root_path is: \\n' + dataset_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the FH model folder for each scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = './Our_Models'\n",
    "per_scene_FH_model_root_path = model_root_path+'\\\\FH\\\\per_scene'\n",
    "print('model_root_path is: \\n' + model_root_path + '\\n')\n",
    "print('per_scene_FH_model_root_path is: \\n' + per_scene_FH_model_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the temporal consistency based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.fuzzy_partition_histogram import FuzzyHistogramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Check the fuzzy histogram based background model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FH_MODEL = FuzzyHistogramModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with FH_MODEL.graph.as_default():\n",
    "    for var in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES ):\n",
    "        print(var.name,var.shape)\n",
    "    print(FH_MODEL.indexing_constant)\n",
    "    for op in tf.get_default_graph().get_operations():\n",
    "        if op.type == \"Placeholder\":\n",
    "            print(op.get_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DeepLab Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.deeplab import DeepLabModel,vis_segmentation,vis_segmentation_map_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = './Our_Models'\n",
    "deeplab_model_path = model_root_path + '\\\\SS_model\\\\deeplab_model.tar.gz'\n",
    "print('deeplab_model_path: \\n',deeplab_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_MODEL = DeepLabModel(deeplab_model_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visualization_local(img_path):\n",
    "    \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
    "    try:\n",
    "        orignal_im = Image.open(img_path)\n",
    "    except IOError:\n",
    "        print('Cannot retrieve image. Please check path: ' + img_path)\n",
    "        return\n",
    "\n",
    "    print('running deeplab on image %s...' % img_path)\n",
    "    resized_im, seg_logits, seg_map = SS_MODEL.run(orignal_im)\n",
    "    print('seg_logits.shape: ',seg_logits.shape)\n",
    "    print('seg_map.shape: ',seg_map.shape)\n",
    "    \n",
    "    vis_segmentation(resized_im, seg_map)\n",
    "\n",
    "img_path = 'in000534.jpg'\n",
    "run_visualization_local(img_path)\n",
    "resized_im, seg_logits, seg_map = SS_MODEL.run(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.synthesis_model_white_box_rectified_F_score import SynthesisModel,calculate_double_mask,single_feature_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_Model = SynthesisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TOP_Model.graph.as_default():\n",
    "    for var in tf.trainable_variables():\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Run for each scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care_catagory_list = ['baseline',\n",
    "                      'dynamicBackground',\n",
    "                      'intermittentObjectMotion',\n",
    "                      'badWeather',\n",
    "                      'shadow',\n",
    "                      'cameraJitter',\n",
    "                      'lowFramerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_scene_FH_model_root_path = model_root_path+'\\\\FH\\\\per_scene'\n",
    "trained_TOP_model_path = './Our_Models\\\\FH\\\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(dataset_root_path):\n",
    "    \n",
    "    relative_path_hierarch_list = root.split('\\\\')[len(dataset_root_path.split('\\\\')):]\n",
    "    level_above_dataset_root_path = len(relative_path_hierarch_list)\n",
    "    \n",
    "    truth_file_list = []\n",
    "    image_file_list = []\n",
    "    result_file_list = []\n",
    "    FH_result_file_list = []\n",
    "    SS_result_file_list = []\n",
    "    \n",
    "    if len(relative_path_hierarch_list) == 2 and relative_path_hierarch_list[0] in care_catagory_list:\n",
    "        \n",
    "        print(relative_path_hierarch_list[1])\n",
    "        \n",
    "        Test_GTs_path = root + '\\\\Test_GTs'\n",
    "        Test_Inputs_path = root + '\\\\Test_Input'\n",
    "        Test_Results_path = root + '\\\\FH_Results'\n",
    "        \n",
    "        FH_model_path = per_scene_FH_model_root_path + '\\\\'+relative_path_hierarch_list[0] + '\\\\' + relative_path_hierarch_list[1] + '\\\\classic_model'\n",
    "        FH_MODEL.load_model(model_path=FH_model_path)\n",
    "        TOP_Model.load_model(model_path=trained_TOP_model_path)\n",
    "        \n",
    "        print('Models loaded.')\n",
    "        \n",
    "        # Get the testing data\n",
    "        for _, _, files in os.walk(Test_GTs_path):\n",
    "            for file in files:\n",
    "                truth_file_list.append(Test_GTs_path+'\\\\'+file)\n",
    "                image_file_list.append(Test_Inputs_path+'\\\\in'+file[2:8]+'.jpg')\n",
    "                result_file_list.append(Test_Results_path+'\\\\result'+file[2:8]+'.png')\n",
    "                FH_result_file_list.append(Test_Results_path+'\\\\FH_result'+file[2:8]+'.png')\n",
    "                SS_result_file_list.append(Test_Results_path+'\\\\SS_result'+file[2:8]+'.png')\n",
    "        \n",
    "        \n",
    "        for image_file,result_file, FH_result_file, SS_result_file in zip(image_file_list,result_file_list,FH_result_file_list,SS_result_file_list):\n",
    "            # Read the image\n",
    "            cv_BGR_image = cv2.resize(cv2.imread(image_file),(320, 240), interpolation = cv2.INTER_CUBIC)\n",
    "            cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_image = cv_gray_image.astype('float')/256.0 # Avoid reaching the 22th bin of a histogram (not using ./255)\n",
    "            cv2.imshow('cv_float_gray_image',cv_float_gray_image)\n",
    "            cv2.waitKey(1)\n",
    "            # FH segmentation\n",
    "            raw_segmentation = FH_MODEL.histogram_checking(cv_float_gray_image)\n",
    "            cv2.imshow('raw_segmentation',raw_segmentation)\n",
    "            cv2.waitKey(1)\n",
    "            # Calculate SS result\n",
    "            Image_image = Image.open(image_file)\n",
    "            _, seg_logits, seg_map = SS_MODEL.run(Image_image)\n",
    "            seg_logits_channel_sum = np.sum(seg_logits,axis=-1)\n",
    "            seg_logits_channel_sum_tile = np.dstack([seg_logits_channel_sum for i in range(seg_logits.shape[-1])])\n",
    "            seg_logits_normalized = seg_logits/seg_logits_channel_sum_tile\n",
    "            seg_map_show = vis_segmentation_map_calculate(seg_map)\n",
    "            cv2.imshow('seg_map_show',seg_map_show)\n",
    "            cv2.waitKey(1)\n",
    "            # Synthesis\n",
    "            composite_feature = np.expand_dims(single_feature_builder(raw_segmentation,seg_logits_normalized),axis=0)\n",
    "            synthesis_result = np.squeeze(TOP_Model.estimate(composite_feature)).clip(0.0,1.0)\n",
    "            synthesis_result_C = cv2.applyColorMap(np.uint8(synthesis_result*255), cv2.COLORMAP_RAINBOW)\n",
    "            cv2.imshow('synthesis_result',synthesis_result_C)\n",
    "            composite_feature_2 = np.expand_dims(single_feature_builder(raw_segmentation*0+0.5,seg_logits_normalized),axis=0)\n",
    "            synthesis_result_2 = np.squeeze(TOP_Model.estimate(composite_feature_2)).clip(0.0,1.0)\n",
    "            synthesis_result_2_C = cv2.applyColorMap(np.uint8(synthesis_result_2*255), cv2.COLORMAP_RAINBOW)\n",
    "            cv2.imshow('synthesis_result_2',synthesis_result_2_C)\n",
    "            composite_feature_3 = np.expand_dims(single_feature_builder(raw_segmentation,seg_logits_normalized*0+1.0/21),axis=0)\n",
    "            synthesis_result_3 = np.squeeze(TOP_Model.estimate(composite_feature_3)).clip(0.0,1.0)\n",
    "            synthesis_result_3_C = cv2.applyColorMap(np.uint8(synthesis_result_3*255), cv2.COLORMAP_RAINBOW)\n",
    "            cv2.imshow('synthesis_result_3',synthesis_result_3_C)\n",
    "            cv2.waitKey(1)\n",
    "            # Record results\n",
    "            cv2.imwrite(result_file,synthesis_result*255)\n",
    "            cv2.imwrite(SS_result_file,synthesis_result_2*255)\n",
    "            cv2.imwrite(FH_result_file,synthesis_result_3*255)\n",
    "            # Update histogram\n",
    "            FH_MODEL.update_histogram(cv_float_gray_image,synthesis_result,train_flag=False)\n",
    "            FH_MODEL.reduce_histogram()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Visualize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "weight_index_list = [i for i in range(len(trainable_variable_list))]\n",
    "weight_name_list = [var.name.split('/')[1]+'_'+var.name.split('/')[1].split(':')[0] for var in trainable_variable_list]\n",
    "weight_value_list = []\n",
    "for value in trainable_variable_value_list:\n",
    "    weight_value_list.append(value)\n",
    "\n",
    "# make figure\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {}\n",
    "}\n",
    "\n",
    "# fill in most of layout\n",
    "#figure['layout']['xaxis'] = {'title': 'Output channel number'}\n",
    "#figure['layout']['yaxis'] = {'title': 'Input channel number'}\n",
    "    \n",
    "# make data\n",
    "observation_data = np.concatenate([weight_value_list[1],weight_value_list[0]],axis=1).T\n",
    "\n",
    "ss_catagory = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "]\n",
    "\n",
    "data_dict = go.Heatmap(z=observation_data,\n",
    "                       x=ss_catagory,\n",
    "                       y=['consistent','inconsistent'],\n",
    "                       colorscale='Viridis')\n",
    "figure['data'].append(data_dict)\n",
    "\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Calculate F-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(result,truth):\n",
    "    pos_mask,neg_mask = calculate_double_mask(truth)\n",
    "    pos_mask = np.squeeze(pos_mask)\n",
    "    neg_mask = np.squeeze(neg_mask)\n",
    "    \n",
    "    TP = np.sum(pos_mask*(1.0-result))\n",
    "    TN = np.sum(neg_mask*result)\n",
    "    FP = np.sum(neg_mask*(1.0-result))\n",
    "    FN = np.sum(pos_mask*result)\n",
    "\n",
    "    Recall = np.maximum(1e-3,TP) / np.maximum(1e-3,TP + FN)\n",
    "    Specificity = np.maximum(1e-3,TN) / np.maximum(1e-3,TN + FP)\n",
    "    PWC = 100.0 * np.maximum(1e-3,FN + FP) / np.maximum(1e-3,TP + FN + FP + TN)\n",
    "    Precision = np.maximum(1e-3,TP) / np.maximum(1e-3,TP + FP)\n",
    "    F_Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
    "    \n",
    "    return TP,TN,FP,FN,Recall,Specificity,PWC,Precision,F_Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_result_score_dict = {}\n",
    "bin_FH_result_score_dict = {}\n",
    "bin_SS_result_score_dict = {}\n",
    "for root, _, files in os.walk(dataset_root_path):\n",
    "    \n",
    "    relative_path_hierarch_list = root.split('\\\\')[len(dataset_root_path.split('\\\\')):]\n",
    "    level_above_dataset_root_path = len(relative_path_hierarch_list)\n",
    "    \n",
    "    truth_file_list = []\n",
    "    image_file_list = []\n",
    "    result_file_list = []\n",
    "    FH_result_file_list = []\n",
    "    SS_result_file_list = []\n",
    "    result_score_list = []\n",
    "    FH_result_score_list = []\n",
    "    SS_result_score_list = []\n",
    "    \n",
    "    if len(relative_path_hierarch_list) == 2 and relative_path_hierarch_list[0] in care_catagory_list:\n",
    "        \n",
    "        print(relative_path_hierarch_list[1])\n",
    "        \n",
    "        Test_GTs_path = root + '\\\\Test_GTs'\n",
    "        Test_Results_path = root + '\\\\FH_Results'\n",
    "        Test_Inputs_path = root + '\\\\Test_Input'\n",
    "        \n",
    "        # Get the files\n",
    "        for _, _, files in os.walk(Test_GTs_path):\n",
    "            for file in files:\n",
    "                truth_file_list.append(Test_GTs_path+'\\\\'+file)\n",
    "                image_file_list.append(Test_Inputs_path+'\\\\in'+file[2:8]+'.jpg')\n",
    "                result_file_list.append(Test_Results_path+'\\\\result'+file[2:8]+'.png')\n",
    "                FH_result_file_list.append(Test_Results_path+'\\\\FH_result'+file[2:8]+'.png')\n",
    "                SS_result_file_list.append(Test_Results_path+'\\\\SS_result'+file[2:8]+'.png')\n",
    "        \n",
    "        \n",
    "        for image_file,truth_file,result_file,FH_result_file,SS_result_file in zip(image_file_list,\n",
    "                                                                                   truth_file_list,\n",
    "                                                                                   result_file_list,\n",
    "                                                                                   FH_result_file_list,\n",
    "                                                                                   SS_result_file_list):\n",
    "            # Read the image\n",
    "            cv_BGR_image = cv2.resize(cv2.imread(image_file),(320, 240), interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imshow('cv_BGR_image',cv_BGR_image)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "            # Load the groundtruth\n",
    "            cv_BGR_truth = cv2.resize(cv2.imread(truth_file),(320, 240), interpolation = cv2.INTER_NEAREST)\n",
    "            cv_gray_truth = cv2.cvtColor(cv_BGR_truth, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow('cv_gray_truth',cv_gray_truth)\n",
    "            cv2.waitKey(1)\n",
    "                    \n",
    "            # Load the result_file\n",
    "            cv_BGR_result = cv2.imread(result_file)\n",
    "            cv_gray_result = cv2.cvtColor(cv_BGR_result, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_result = cv_gray_result.astype('float')/255.0 \n",
    "            cv_float_bin_result = cv_float_gray_result\n",
    "            cv_float_bin_result[cv_float_bin_result>=0.5]=1.0\n",
    "            cv_float_bin_result[cv_float_bin_result<0.5]=0.0\n",
    "            cv2.imshow('cv_float_bin_result',cv_float_bin_result)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "            # Load the FH_result_file\n",
    "            cv_BGR_FH_result = cv2.imread(FH_result_file)\n",
    "            cv_gray_FH_result = cv2.cvtColor(cv_BGR_FH_result, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_FH_result = cv_gray_FH_result.astype('float')/255.0\n",
    "            cv_float_bin_FH_result = cv_float_gray_FH_result\n",
    "            cv_float_bin_FH_result[cv_float_bin_FH_result>=0.5]=1.0\n",
    "            cv_float_bin_FH_result[cv_float_bin_FH_result<0.5]=0.0\n",
    "            cv2.imshow('cv_float_bin_FH_result',cv_float_bin_FH_result)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            # Load the SS_result_file\n",
    "            cv_BGR_SS_result = cv2.imread(SS_result_file)\n",
    "            cv_gray_SS_result = cv2.cvtColor(cv_BGR_SS_result, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_SS_result = cv_gray_SS_result.astype('float')/255.0 \n",
    "            cv_float_bin_SS_result = cv_float_gray_SS_result\n",
    "            cv_float_bin_SS_result[cv_float_bin_SS_result>=0.666666]=1.0\n",
    "            cv_float_bin_SS_result[cv_float_bin_SS_result<0.666666]=0.0\n",
    "            cv2.imshow('cv_float_bin_SS_result',cv_float_bin_SS_result)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            result_score_list.append(np.array(calculate_scores(cv_float_bin_result,cv_gray_truth)))\n",
    "            FH_result_score_list.append(np.array(calculate_scores(cv_float_bin_FH_result,cv_gray_truth)))\n",
    "            SS_result_score_list.append(np.array(calculate_scores(cv_float_bin_SS_result,cv_gray_truth)))\n",
    "        \n",
    "        # Record scores for the cato.\n",
    "        bin_result_score_dict[relative_path_hierarch_list[1]] = result_score_list\n",
    "        bin_FH_result_score_dict[relative_path_hierarch_list[1]] = FH_result_score_list\n",
    "        bin_SS_result_score_dict[relative_path_hierarch_list[1]] = SS_result_score_list\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_result_with_objects_mean_score_dict = {}\n",
    "bin_FH_result_with_objects_mean_score_dict = {}\n",
    "bin_SS_result_with_objects_mean_score_dict = {}\n",
    "for key in bin_result_score_dict.keys():\n",
    "    bin_result_with_objects_mean_score_dict[key] = np.mean(np.array(bin_result_score_dict[key])[(np.array(bin_result_score_dict[key])[:,0]+np.array(bin_result_score_dict[key])[:,3])>0,:],axis=0)\n",
    "for key in bin_FH_result_score_dict.keys():\n",
    "    bin_FH_result_with_objects_mean_score_dict[key] = np.mean(np.array(bin_FH_result_score_dict[key])[(np.array(bin_FH_result_score_dict[key])[:,0]+np.array(bin_FH_result_score_dict[key])[:,3])>0,:],axis=0)\n",
    "for key in bin_SS_result_score_dict.keys():\n",
    "    bin_SS_result_with_objects_mean_score_dict[key] = np.mean(np.array(bin_SS_result_score_dict[key])[(np.array(bin_SS_result_score_dict[key])[:,0]+np.array(bin_SS_result_score_dict[key])[:,3])>0,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=[key for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_result_with_objects_mean_score_dict[key][-1] for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    name='F-scores of results using fused information',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=[key for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_FH_result_with_objects_mean_score_dict[key][-1] for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    name='F-scores of results using only temporal consistency',\n",
    "    marker=dict(\n",
    "        color='rgb(245,130,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=[key for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_SS_result_with_objects_mean_score_dict[key][-1] for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    name='F-scores of results using only semantic information',\n",
    "    marker=dict(\n",
    "        color='rgb(45,230,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average boost for F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_A = np.array([bin_result_with_objects_mean_score_dict[key][-1] for key in bin_result_with_objects_mean_score_dict.keys()])\n",
    "score_B = np.array([bin_FH_result_with_objects_mean_score_dict[key][-1] for key in bin_FH_result_with_objects_mean_score_dict.keys()])\n",
    "score_C = np.array([bin_SS_result_with_objects_mean_score_dict[key][-1] for key in bin_SS_result_with_objects_mean_score_dict.keys()])\n",
    "print(np.mean((score_A-score_B)/(score_B)))\n",
    "print(np.mean((score_A-score_C)/(score_C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Check the Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=[key for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_result_with_objects_mean_score_dict[key][4] for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Recall of of results using fused information',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=[key for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_FH_result_with_objects_mean_score_dict[key][4] for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Recall of results using only temporal consistency',\n",
    "    marker=dict(\n",
    "        color='rgb(245,130,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=[key for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_SS_result_with_objects_mean_score_dict[key][4] for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Recall of results using only semantic information',\n",
    "    marker=dict(\n",
    "        color='rgb(45,230,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_A = np.array([bin_result_with_objects_mean_score_dict[key][4] for key in bin_result_with_objects_mean_score_dict.keys()])\n",
    "recall_B = np.array([bin_FH_result_with_objects_mean_score_dict[key][4] for key in bin_FH_result_with_objects_mean_score_dict.keys()])\n",
    "recall_C = np.array([bin_SS_result_with_objects_mean_score_dict[key][4] for key in bin_SS_result_with_objects_mean_score_dict.keys()])\n",
    "print(np.mean((recall_A-recall_B)/(recall_B)))\n",
    "print(np.mean((recall_A-recall_C)/(recall_C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=[key for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_result_with_objects_mean_score_dict[key][-2] for key in bin_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Precision of of results using fused information',\n",
    "    marker=dict(\n",
    "        color='rgb(49,130,189)'\n",
    "    )\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=[key for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_FH_result_with_objects_mean_score_dict[key][-2] for key in bin_FH_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Precision of results using only temporal consistency',\n",
    "    marker=dict(\n",
    "        color='rgb(245,130,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=[key for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    y=[bin_SS_result_with_objects_mean_score_dict[key][-2] for key in bin_SS_result_with_objects_mean_score_dict.keys()],\n",
    "    name='Precision of results using only semantic information',\n",
    "    marker=dict(\n",
    "        color='rgb(45,230,45)'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_A = np.array([bin_result_with_objects_mean_score_dict[key][-2] for key in bin_result_with_objects_mean_score_dict.keys()])\n",
    "prec_B = np.array([bin_FH_result_with_objects_mean_score_dict[key][-2] for key in bin_FH_result_with_objects_mean_score_dict.keys()])\n",
    "prec_C = np.array([bin_SS_result_with_objects_mean_score_dict[key][-2] for key in bin_SS_result_with_objects_mean_score_dict.keys()])\n",
    "print(np.mean((prec_A-prec_B)/(prec_B)))\n",
    "print(np.mean((prec_A-prec_C)/(prec_C)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
