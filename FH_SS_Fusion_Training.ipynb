{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A universal framework for fusing semantic information and temporal consistency for background segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrate the training process of the temporal consistency based model and the top model. The training of the DeepLab model is not proposed here.\n",
    "\n",
    "---by Zhi Zeng Sep.,28,2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train the temporal consistency-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = './Ours_Dataset'\n",
    "print('dataset_root_path is: \\n' + dataset_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = './Our_Models'\n",
    "per_scene_FH_model_root_path = model_root_path+'\\\\FH\\\\per_scene'\n",
    "print('model_root_path is: \\n' + model_root_path + '\\n')\n",
    "print('per_scene_FH_model_root_path is: \\n' + per_scene_FH_model_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.fuzzy_partition_histogram import FuzzyHistogramModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FH_MODEL = FuzzyHistogramModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Check the fuzzy histogram based background model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with FH_MODEL.graph.as_default():\n",
    "    for var in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES ):\n",
    "        print(var.name,var.shape)\n",
    "    print(FH_MODEL.indexing_constant)\n",
    "    for op in tf.get_default_graph().get_operations():\n",
    "        if op.type == \"Placeholder\":\n",
    "            print(op.get_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Train the model for each scene with 200 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for root, _, files in os.walk(dataset_root_path):\n",
    "    relative_path_hierarch_list = root.split('\\\\')[len(dataset_root_path.split('\\\\')):]\n",
    "    level_above_dataset_root_path = len(relative_path_hierarch_list)\n",
    "    if len(relative_path_hierarch_list) == 2:\n",
    "        # Get the training data\n",
    "        Train_GTs_path = root + '\\\\Train_GTs'\n",
    "        Train_Inputs_path = root + '\\\\Train_Inputs'\n",
    "        FH_model_path = per_scene_FH_model_root_path + '\\\\'+relative_path_hierarch_list[0] + '\\\\' + relative_path_hierarch_list[1] + '\\\\classic_model'\n",
    "        per_scene_TOP_model_path = per_scene_FH_model_root_path + '\\\\'+relative_path_hierarch_list[0] + '\\\\' + relative_path_hierarch_list[1] + '\\\\DNN_model'\n",
    "        truth_file_list = []\n",
    "        image_file_list = []\n",
    "        for _, _, files in os.walk(Train_GTs_path):\n",
    "            for file in files:\n",
    "                truth_file_list.append(Train_GTs_path+'\\\\'+file)\n",
    "                image_file_list.append(Train_Inputs_path+'\\\\in'+file[2:8]+'.jpg')\n",
    "        # Initialize the model\n",
    "        FH_MODEL.initialize_sess()\n",
    "        # Train the model\n",
    "        for image_file,truth_file in zip(image_file_list,truth_file_list):\n",
    "            # Read the image\n",
    "            cv_BGR_image = cv2.resize(cv2.imread(image_file),(320, 240), interpolation = cv2.INTER_CUBIC)\n",
    "            cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_image = cv_gray_image.astype('float')/256.0 # Avoid reaching the 22th bin of a histogram (do not using ./255)\n",
    "            cv2.imshow('cv_float_gray_image',cv_float_gray_image)\n",
    "            cv2.waitKey(1)\n",
    "            # Load the groundtruth\n",
    "            cv_BGR_truth = cv2.resize(cv2.imread(truth_file),(320, 240), interpolation = cv2.INTER_NEAREST)\n",
    "            cv_gray_truth = cv2.cvtColor(cv_BGR_truth, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_truth = 1.0-cv_gray_truth.astype('float')/255.0 \n",
    "            cv2.imshow('cv_float_gray_truth',cv_float_gray_truth)\n",
    "            # Check the histogram\n",
    "            raw_segmentation = FH_MODEL.histogram_checking(cv_float_gray_image)\n",
    "            cv2.imshow('raw_segmentation',raw_segmentation)\n",
    "            cv2.waitKey(10)\n",
    "            # Update the histogram\n",
    "            FH_MODEL.update_histogram(cv_float_gray_image,cv_float_gray_truth,train_flag=True)\n",
    "        FH_MODEL.reduce_histogram()\n",
    "        cv2.destroyAllWindows()\n",
    "        # Save the model\n",
    "        FH_MODEL.save_model(FH_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Run over the model on training frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: These results combined with semantic segmentaions are used to train the top model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(dataset_root_path):\n",
    "    relative_path_hierarch_list = root.split('\\\\')[len(dataset_root_path.split('\\\\')):]\n",
    "    level_above_dataset_root_path = len(relative_path_hierarch_list)\n",
    "    if len(relative_path_hierarch_list) == 2:\n",
    "        # Get the training data\n",
    "        Train_GTs_path = root + '\\\\Train_GTs'\n",
    "        Train_Inputs_path = root + '\\\\Train_Inputs'\n",
    "        FH_Training_Results_path = root + '\\\\FH_Training_Results'\n",
    "        FH_model_path = per_scene_FH_model_root_path + '\\\\'+relative_path_hierarch_list[0] + '\\\\' + relative_path_hierarch_list[1] + '\\\\classic_model'\n",
    "        per_scene_TOP_model_path = per_scene_FH_model_root_path + '\\\\'+relative_path_hierarch_list[0] + '\\\\' + relative_path_hierarch_list[1] + '\\\\DNN_model'\n",
    "        truth_file_list = []\n",
    "        image_file_list = []\n",
    "        result_file_list = []\n",
    "        for _, _, files in os.walk(Train_GTs_path):\n",
    "            for file in files:\n",
    "                truth_file_list.append(Train_GTs_path+'\\\\'+file)\n",
    "                image_file_list.append(Train_Inputs_path+'\\\\in'+file[2:8]+'.jpg')\n",
    "                result_file_list.append(FH_Training_Results_path+'\\\\result'+file[2:8]+'.png')\n",
    "        # Initialize the model\n",
    "        FH_MODEL.initialize_sess()\n",
    "        FH_MODEL.load_model(FH_model_path)\n",
    "        # Train the model\n",
    "        for image_file,truth_file,result_file in zip(image_file_list,truth_file_list,result_file_list):\n",
    "            # Read the image\n",
    "            cv_BGR_image = cv2.resize(cv2.imread(image_file),(320, 240), interpolation = cv2.INTER_CUBIC)\n",
    "            cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_image = cv_gray_image.astype('float')/256.0 # Avoid reaching the 22th bin of a histogram (do not using ./255)\n",
    "            cv2.imshow('cv_float_gray_image',cv_float_gray_image)\n",
    "            cv2.waitKey(1)\n",
    "            # Load the groundtruth\n",
    "            cv_BGR_truth = cv2.resize(cv2.imread(truth_file),(320, 240), interpolation = cv2.INTER_NEAREST)\n",
    "            cv_gray_truth = cv2.cvtColor(cv_BGR_truth, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_truth = 1.0-cv_gray_truth.astype('float')/255.0 \n",
    "            cv2.imshow('cv_float_gray_truth',cv_float_gray_truth)\n",
    "            # Check the histogram\n",
    "            raw_segmentation = FH_MODEL.histogram_checking(cv_float_gray_image)\n",
    "            cv2.imshow('raw_segmentation',raw_segmentation)\n",
    "            cv2.waitKey(10)\n",
    "            # Record the performance of the model\n",
    "            cv2.imwrite(result_file,raw_segmentation*255)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DeepLab Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.deeplab import DeepLabModel,vis_segmentation,vis_segmentation_map_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = './Our_Models'\n",
    "deeplab_model_path = model_root_path + '\\\\SS_model\\\\deeplab_model.tar.gz'\n",
    "print('deeplab_model_path: \\n',deeplab_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_MODEL = DeepLabModel(deeplab_model_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visualization_local(img_path):\n",
    "    \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
    "    try:\n",
    "        orignal_im = Image.open(img_path)\n",
    "    except IOError:\n",
    "        print('Cannot retrieve image. Please check path: ' + img_path)\n",
    "        return\n",
    "\n",
    "    print('running deeplab on image %s...' % img_path)\n",
    "    resized_im, seg_logits, seg_map = SS_MODEL.run(orignal_im)\n",
    "    print('seg_logits.shape: ',seg_logits.shape)\n",
    "    print('seg_map.shape: ',seg_map.shape)\n",
    "    \n",
    "    vis_segmentation(resized_im, seg_map)\n",
    "\n",
    "img_path = 'in000534.jpg'\n",
    "run_visualization_local(img_path)\n",
    "resized_im, seg_logits, seg_map = SS_MODEL.run(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.synthesis_model_white_box_rectified_F_score import SynthesisModel,calculate_double_mask,single_feature_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_Model = SynthesisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TOP_Model.graph.as_default():\n",
    "    for var in tf.trainable_variables():\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Training on a batch of images for model for each scene with 200 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care_catagory_list = ['baseline',\n",
    "                      'dynamicBackground',\n",
    "                      'intermittentObjectMotion',\n",
    "                      'badWeather',\n",
    "                      'shadow',\n",
    "                      'cameraJitter',\n",
    "                      'lowFramerate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_file_list = []\n",
    "image_file_list = []\n",
    "result_file_list = []\n",
    "\n",
    "for root, _, files in os.walk(dataset_root_path):\n",
    "    \n",
    "    relative_path_hierarch_list = root.split('\\\\')[len(dataset_root_path.split('\\\\')):]\n",
    "    level_above_dataset_root_path = len(relative_path_hierarch_list)\n",
    "    \n",
    "    if len(relative_path_hierarch_list) == 2 and relative_path_hierarch_list[0] in care_catagory_list:\n",
    "        \n",
    "        Train_GTs_path = root + '\\\\Train_GTs'\n",
    "        Train_Inputs_path = root + '\\\\Train_Inputs'\n",
    "        FH_Training_Results_path = root + '\\\\FH_Training_Results'\n",
    "\n",
    "        # Get the training data\n",
    "        for _, _, files in os.walk(Train_GTs_path):\n",
    "            for file in files:\n",
    "                truth_file_list.append(Train_GTs_path+'\\\\'+file)\n",
    "                image_file_list.append(Train_Inputs_path+'\\\\in'+file[2:8]+'.jpg')\n",
    "                result_file_list.append(FH_Training_Results_path+'\\\\result'+file[2:8]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of truth files is:',len(truth_file_list))\n",
    "print('Number of image files is:',len(image_file_list))\n",
    "print('Number of result files is:',len(result_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "TOP_model_path = './Our_Models\\\\FH\\\\model'\n",
    "TOP_Model.initialize_sess(log_path=TOP_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 50\n",
    "num_batchs = len(image_file_list)//batch_size -1\n",
    "\n",
    "temp_count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    image_file_list_shuffled, truth_file_list_shuffled, result_file_list_shuffled = shuffle(image_file_list, \n",
    "                                                                                            truth_file_list, \n",
    "                                                                                            result_file_list, \n",
    "                                                                                            random_state=epoch)\n",
    "    for batch_num in range(num_batchs):\n",
    "        image_batch_file_list = image_file_list_shuffled[batch_num*batch_size:(1+batch_num)*batch_size]\n",
    "        truth_batch_file_list = truth_file_list_shuffled[batch_num*batch_size:(1+batch_num)*batch_size]\n",
    "        result_batch_file_list = result_file_list_shuffled[batch_num*batch_size:(1+batch_num)*batch_size]\n",
    "        composit_feature_batch = []\n",
    "        positive_mask_batch = []\n",
    "        negative_mask_batch = []\n",
    "        # Build the learning batch\n",
    "        for image_file,truth_file,result_file in zip(image_batch_file_list,truth_batch_file_list,result_batch_file_list):\n",
    "            # Read the image\n",
    "            cv_BGR_image = cv2.resize(cv2.imread(image_file),(320, 240), interpolation = cv2.INTER_CUBIC)\n",
    "            cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_image = cv_gray_image.astype('float')/256.0 # Avoid reaching the 22th bin of a histogram (not using ./255)\n",
    "            cv2.imshow('cv_float_gray_image',cv_float_gray_image)\n",
    "            cv2.waitKey(1)\n",
    "            # Load the groundtruth\n",
    "            cv_BGR_truth = cv2.resize(cv2.imread(truth_file),(320, 240), interpolation = cv2.INTER_NEAREST)\n",
    "            cv_gray_truth = cv2.cvtColor(cv_BGR_truth, cv2.COLOR_BGR2GRAY)\n",
    "            cv_float_gray_truth = 1.0-cv_gray_truth.astype('float')/255.0 \n",
    "            cv2.imshow('cv_float_gray_truth',cv_float_gray_truth)\n",
    "            # Load the result\n",
    "            cv_BGR_result = cv2.imread(result_file)\n",
    "            cv_gray_result = cv2.cvtColor(cv_BGR_result, cv2.COLOR_BGR2GRAY)\n",
    "            raw_segmentation = cv_gray_result.astype('float')/255.0 \n",
    "            cv2.imshow('raw_segmentation',raw_segmentation)\n",
    "            cv2.waitKey(1)\n",
    "            # Calculate SS result\n",
    "            Image_image = Image.open(image_file)\n",
    "            _, seg_logits, seg_map = SS_MODEL.run(Image_image)\n",
    "            seg_logits_channel_sum = np.sum(seg_logits,axis=-1)\n",
    "            seg_logits_channel_sum_tile = np.dstack([seg_logits_channel_sum for i in range(seg_logits.shape[-1])])\n",
    "            seg_logits_normalized = seg_logits/seg_logits_channel_sum_tile\n",
    "            seg_map_show = vis_segmentation_map_calculate(seg_map)\n",
    "            cv2.imshow('seg_map_show',seg_map_show)\n",
    "            cv2.waitKey(1)\n",
    "            # Calculate double masks\n",
    "            positive_mask,negative_mask = calculate_double_mask(cv_gray_truth)\n",
    "            cv2.imshow('positive_mask',positive_mask)\n",
    "            cv2.imshow('negative_mask',negative_mask)\n",
    "            cv2.waitKey(1)\n",
    "            composit_feature_batch.append(single_feature_builder(raw_segmentation,seg_logits_normalized))\n",
    "            positive_mask_batch.append(positive_mask)\n",
    "            negative_mask_batch.append(negative_mask)\n",
    "\n",
    "        # Learning\n",
    "        current_loss,synthesis_result = TOP_Model.train(composit_feature_batch,\n",
    "                                                        positive_mask_batch,\n",
    "                                                        negative_mask_batch,\n",
    "                                                        step=temp_count)\n",
    "        cv2.imshow('synthesis_result',synthesis_result[0])\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        temp_count += 1\n",
    "        if temp_count%50==1:\n",
    "            print('temp_count: ',temp_count,'current_loss:',current_loss)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "TOP_Model.save_model(TOP_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
